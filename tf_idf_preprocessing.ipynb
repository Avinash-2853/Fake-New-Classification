{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa571a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4bd17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed/train.csv\", converters={'tokens': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6415f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOILER ROOM: As the Frogs Slowly Boil – EP #40</td>\n",
       "      <td>Tune in to the Alternate Current Radio Network...</td>\n",
       "      <td>US_News</td>\n",
       "      <td>January 20, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>boiler room: as the frogs slowly boil – ep #40...</td>\n",
       "      <td>[boiler, room, frog, slowly, boil, ep, tune, a...</td>\n",
       "      <td>boiler room frog slowly boil ep tune alternate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Venezuela oil boss to give military more P...</td>\n",
       "      <td>CARACAS (Reuters) - A general appointed at the...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 27, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>new venezuela oil boss to give military more p...</td>\n",
       "      <td>[new, venezuela, oil, bos, give, military, pdv...</td>\n",
       "      <td>new venezuela oil bos give military pdvsa post...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkey says talk of ending its EU accession un...</td>\n",
       "      <td>ISTANBUL (Reuters) - Turkey s European Union A...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 4, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>turkey says talk of ending its eu accession un...</td>\n",
       "      <td>[turkey, say, talk, ending, eu, accession, und...</td>\n",
       "      <td>turkey say talk ending eu accession undermines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENATOR GILLIBRAND Pulled Strings So Muslim At...</td>\n",
       "      <td>Democrat Senator Kristen Gillibrand (NY) likes...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Dec 12, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>senator gillibrand pulled strings so muslim at...</td>\n",
       "      <td>[senator, gillibrand, pulled, string, muslim, ...</td>\n",
       "      <td>senator gillibrand pulled string muslim athlet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Republican Trump says 'system is rigged' after...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. Republican preside...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 5, 2016</td>\n",
       "      <td>1</td>\n",
       "      <td>republican trump says 'system is rigged' after...</td>\n",
       "      <td>[republican, trump, say, rigged, clinton, emai...</td>\n",
       "      <td>republican trump say rigged clinton email anno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35913</th>\n",
       "      <td>Trump Just FAILED Hundreds Of Manufacturing W...</td>\n",
       "      <td>Last year, Trump claimed he was succeeding at ...</td>\n",
       "      <td>News</td>\n",
       "      <td>May 7, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>trump just failed hundreds of manufacturing w...</td>\n",
       "      <td>[trump, failed, hundred, manufacturing, worker...</td>\n",
       "      <td>trump failed hundred manufacturing worker blam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35914</th>\n",
       "      <td>Judge Garland not interested in FBI job: sources</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. appeals court judg...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>May 16, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>judge garland not interested in fbi job: sourc...</td>\n",
       "      <td>[judge, garland, interested, fbi, job, source,...</td>\n",
       "      <td>judge garland interested fbi job source washin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35915</th>\n",
       "      <td>Expert On Voting Fraud DESTROYS Trump’s Lies ...</td>\n",
       "      <td>Terrified and unable to accept that he s destr...</td>\n",
       "      <td>News</td>\n",
       "      <td>October 17, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>expert on voting fraud destroys trump’s lies ...</td>\n",
       "      <td>[expert, voting, fraud, destroys, trump, lie, ...</td>\n",
       "      <td>expert voting fraud destroys trump lie blister...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35916</th>\n",
       "      <td>[Video] POLICE HAVE VERY GOOD REASON FOR BLOCK...</td>\n",
       "      <td>This mayor s involvement in potential illegal ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Apr 24, 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>[video] police have very good reason for block...</td>\n",
       "      <td>[video, police, good, reason, blocking, newly,...</td>\n",
       "      <td>video police good reason blocking newly electe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35917</th>\n",
       "      <td>BUSTED! WASHINGTON POST Skips Maxine Waters’ A...</td>\n",
       "      <td>There are 20 Democrats who at certain times ha...</td>\n",
       "      <td>politics</td>\n",
       "      <td>May 10, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>busted! washington post skips maxine waters’ a...</td>\n",
       "      <td>[busted, washington, post, skip, maxine, water...</td>\n",
       "      <td>busted washington post skip maxine water admis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35918 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0         BOILER ROOM: As the Frogs Slowly Boil – EP #40   \n",
       "1      New Venezuela oil boss to give military more P...   \n",
       "2      Turkey says talk of ending its EU accession un...   \n",
       "3      SENATOR GILLIBRAND Pulled Strings So Muslim At...   \n",
       "4      Republican Trump says 'system is rigged' after...   \n",
       "...                                                  ...   \n",
       "35913   Trump Just FAILED Hundreds Of Manufacturing W...   \n",
       "35914   Judge Garland not interested in FBI job: sources   \n",
       "35915   Expert On Voting Fraud DESTROYS Trump’s Lies ...   \n",
       "35916  [Video] POLICE HAVE VERY GOOD REASON FOR BLOCK...   \n",
       "35917  BUSTED! WASHINGTON POST Skips Maxine Waters’ A...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "0      Tune in to the Alternate Current Radio Network...       US_News   \n",
       "1      CARACAS (Reuters) - A general appointed at the...     worldnews   \n",
       "2      ISTANBUL (Reuters) - Turkey s European Union A...     worldnews   \n",
       "3      Democrat Senator Kristen Gillibrand (NY) likes...     left-news   \n",
       "4      WASHINGTON (Reuters) - U.S. Republican preside...  politicsNews   \n",
       "...                                                  ...           ...   \n",
       "35913  Last year, Trump claimed he was succeeding at ...          News   \n",
       "35914  WASHINGTON (Reuters) - U.S. appeals court judg...  politicsNews   \n",
       "35915  Terrified and unable to accept that he s destr...          News   \n",
       "35916  This mayor s involvement in potential illegal ...      politics   \n",
       "35917  There are 20 Democrats who at certain times ha...      politics   \n",
       "\n",
       "                     date  label  \\\n",
       "0        January 20, 2016      0   \n",
       "1      November 27, 2017       1   \n",
       "2      September 4, 2017       1   \n",
       "3            Dec 12, 2017      0   \n",
       "4           July 5, 2016       1   \n",
       "...                   ...    ...   \n",
       "35913         May 7, 2017      0   \n",
       "35914       May 16, 2017       1   \n",
       "35915    October 17, 2016      0   \n",
       "35916        Apr 24, 2015      0   \n",
       "35917        May 10, 2017      0   \n",
       "\n",
       "                                                 content  \\\n",
       "0      boiler room: as the frogs slowly boil – ep #40...   \n",
       "1      new venezuela oil boss to give military more p...   \n",
       "2      turkey says talk of ending its eu accession un...   \n",
       "3      senator gillibrand pulled strings so muslim at...   \n",
       "4      republican trump says 'system is rigged' after...   \n",
       "...                                                  ...   \n",
       "35913   trump just failed hundreds of manufacturing w...   \n",
       "35914  judge garland not interested in fbi job: sourc...   \n",
       "35915   expert on voting fraud destroys trump’s lies ...   \n",
       "35916  [video] police have very good reason for block...   \n",
       "35917  busted! washington post skips maxine waters’ a...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [boiler, room, frog, slowly, boil, ep, tune, a...   \n",
       "1      [new, venezuela, oil, bos, give, military, pdv...   \n",
       "2      [turkey, say, talk, ending, eu, accession, und...   \n",
       "3      [senator, gillibrand, pulled, string, muslim, ...   \n",
       "4      [republican, trump, say, rigged, clinton, emai...   \n",
       "...                                                  ...   \n",
       "35913  [trump, failed, hundred, manufacturing, worker...   \n",
       "35914  [judge, garland, interested, fbi, job, source,...   \n",
       "35915  [expert, voting, fraud, destroys, trump, lie, ...   \n",
       "35916  [video, police, good, reason, blocking, newly,...   \n",
       "35917  [busted, washington, post, skip, maxine, water...   \n",
       "\n",
       "                                              clean_text  \n",
       "0      boiler room frog slowly boil ep tune alternate...  \n",
       "1      new venezuela oil bos give military pdvsa post...  \n",
       "2      turkey say talk ending eu accession undermines...  \n",
       "3      senator gillibrand pulled string muslim athlet...  \n",
       "4      republican trump say rigged clinton email anno...  \n",
       "...                                                  ...  \n",
       "35913  trump failed hundred manufacturing worker blam...  \n",
       "35914  judge garland interested fbi job source washin...  \n",
       "35915  expert voting fraud destroys trump lie blister...  \n",
       "35916  video police good reason blocking newly electe...  \n",
       "35917  busted washington post skip maxine water admis...  \n",
       "\n",
       "[35918 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbd5413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n-gram range: (1, 3)\n",
      "Best F1 score: 0.9762636427806706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Use actual data from df\n",
    "# X: texts; y: assume 'label' column holds labels (change if different)\n",
    "X = df['clean_text'].values\n",
    "y = df['label'].values  # <-- Make sure to replace with correct label column if it's different\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "pipeline.named_steps['tfidf'].set_params(max_features=10000)\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1,1), (1,2), (1,3)]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"Best n-gram range:\", grid.best_params_['tfidf__ngram_range'])\n",
    "print(\"Best F1 score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777cf488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "\n",
    "# Apply TF-IDF feature engineering with ngram_range (1,3) and max_features=10000\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 3), max_features=10000)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['clean_text'].values)\n",
    "\n",
    "# Save the TF-IDF matrix and the vectorizer as a tuple to pickle file\n",
    "with open('tfidf_features_ngram_1_1.pkl', 'wb') as f:\n",
    "    pickle.dump((tfidf_features, tfidf_vectorizer), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b059ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/home/root495/Inexture/Fake New Detection/tfidf_features_ngram_1_1.pkl', 'rb') as f:\n",
    "    tfidf_features, tfidf_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68ecaec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE: {0: 18771, 1: 18771}\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Use the same X and y as above\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(tfidf_features, df['label'].values)\n",
    "\n",
    "print(\"Class distribution after SMOTE:\", dict(zip(*np.unique(y_res, return_counts=True))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "288bf5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"data/processed/test.csv\")\n",
    "\n",
    "# Transform test data into TF-IDF representation using the fitted vectorizer\n",
    "X_test = tfidf_vectorizer.transform(test_df['clean_text'].values)\n",
    "y_test = test_df[\"label\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce68c16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression parameters: {'C': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Best F1 score from Logistic Regression: 0.9947564619956404\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Use the TF-IDF features already computed\n",
    "X_tfidf = tfidf_features\n",
    "y = df['label'].values  # Make sure this matches your label column name\n",
    "\n",
    "# Set up the Logistic Regression and parameter grid\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'saga']\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best Logistic Regression parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 score from Logistic Regression:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ff40415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression metrics on test data:\n",
      "Precision: 0.9939067260370283\n",
      "Recall: 0.993208430913349\n",
      "F1 Score: 0.9935574557807192\n",
      "Accuracy: 0.9938752783964365\n",
      "ROC-AUC: 0.9995211742418593\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "# Train logistic regression on balanced data with the best parameters found\n",
    "logreg = LogisticRegression(\n",
    "    max_iter=1000, \n",
    "    random_state=42,\n",
    "    C=100, \n",
    "    penalty='l2', \n",
    "    solver='saga'\n",
    ")\n",
    "logreg.fit(X_res, y_res)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "y_test_proba = logreg.predict_proba(X_test)[:,1] \n",
    "\n",
    "print(\"Logistic Regression metrics on test data:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "918303e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Naive Bayes parameters: {'alpha': 0.01, 'fit_prior': True}\n",
      "Best F1 score from Naive Bayes: 0.954099340436948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Set up the Naive Bayes classifier and parameter grid\n",
    "nb = MultinomialNB()\n",
    "nb_param_grid = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1, 2, 5, 10],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "nb_grid_search = GridSearchCV(nb, nb_param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "nb_grid_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best Naive Bayes parameters:\", nb_grid_search.best_params_)\n",
    "print(\"Best F1 score from Naive Bayes:\", nb_grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77bb1db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes metrics on test data:\n",
      "Precision: 0.9481756913781083\n",
      "Recall: 0.955503512880562\n",
      "F1 Score: 0.9518254986585792\n",
      "Accuracy: 0.9540089086859688\n",
      "ROC-AUC: 0.9892438729694655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Train Naive Bayes with best parameters\n",
    "nb_best = MultinomialNB(alpha=0.01, fit_prior=True)\n",
    "nb_best.fit(X_res, y_res)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred_nb = nb_best.predict(X_test)\n",
    "y_test_proba_nb = nb_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Naive Bayes metrics on test data:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred_nb))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred_nb))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred_nb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_nb))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee40c643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Best F1 score from Decision Tree: 0.9954486602167261\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Set up the Decision Tree classifier and parameter grid\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt_param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [None, 5, 10, 20, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "dt_grid_search = GridSearchCV(dt, dt_param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "dt_grid_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best Decision Tree parameters:\", dt_grid_search.best_params_)\n",
    "print(\"Best F1 score from Decision Tree:\", dt_grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349e97e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree metrics on test data:\n",
      "Precision: 0.9939252336448599\n",
      "Recall: 0.9962529274004683\n",
      "F1 Score: 0.9950877192982456\n",
      "Accuracy: 0.9953229398663697\n",
      "ROC-AUC: 0.9947571562821642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train Decision Tree with best parameters\n",
    "dt_best = DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=5,\n",
    "    random_state=42\n",
    ")\n",
    "dt_best.fit(X_res, y_res)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred_dt = dt_best.predict(X_test)\n",
    "y_test_proba_dt = dt_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Decision Tree metrics on test data:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred_dt))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred_dt))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred_dt))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_dt))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d68002bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best Random Forest parameters from RandomizedSearchCV: {'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
      "Best F1 score from Random Forest (RandomizedSearchCV): 0.9975268103645627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set up the Random Forest classifier and parameter distributions\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'max_depth': [None, 5, 10, 20, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    rf,\n",
    "    rf_param_dist,\n",
    "    n_iter=2,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "rf_random_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best Random Forest parameters from RandomizedSearchCV:\", rf_random_search.best_params_)\n",
    "print(\"Best F1 score from Random Forest (RandomizedSearchCV):\", rf_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51373692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest metrics on test data:\n",
      "Precision: 0.9967220791383751\n",
      "Recall: 0.9969555035128805\n",
      "F1 Score: 0.9968387776606955\n",
      "Accuracy: 0.9969933184855234\n",
      "ROC-AUC: 0.9998080221960353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest with best parameters from RandomizedSearchCV\n",
    "rf_best = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    "    max_depth=None,\n",
    "    bootstrap=False,\n",
    "    random_state=42\n",
    ")\n",
    "rf_best.fit(X_res, y_res)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred_rf = rf_best.predict(X_test)\n",
    "y_test_proba_rf = rf_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest metrics on test data:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_rf))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_rf)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef586d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost parameters from RandomizedSearchCV: {'n_estimators': 50, 'learning_rate': 0.05, 'algorithm': 'SAMME'}\n",
      "Best F1 score from AdaBoost (RandomizedSearchCV): 0.9931889808956736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set up the AdaBoost classifier and parameter distributions\n",
    "ada = AdaBoostClassifier(random_state=42)\n",
    "ada_param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0, 2.0],\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "ada_random_search = RandomizedSearchCV(\n",
    "    ada,\n",
    "    ada_param_dist,\n",
    "    n_iter=2,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "ada_random_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best AdaBoost parameters from RandomizedSearchCV:\", ada_random_search.best_params_)\n",
    "print(\"Best F1 score from AdaBoost (RandomizedSearchCV):\", ada_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a785185c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost metrics on test data:\n",
      "Precision: 0.9886258124419685\n",
      "Recall: 0.997423887587822\n",
      "F1 Score: 0.9930053625553742\n",
      "Accuracy: 0.9933184855233853\n",
      "ROC-AUC: 0.997134677824351\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Train AdaBoost with best parameters from RandomizedSearchCV\n",
    "ada_best = AdaBoostClassifier(\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.05,\n",
    "    algorithm='SAMME',\n",
    "    random_state=42\n",
    ")\n",
    "ada_best.fit(X_res, y_res)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred_ada = ada_best.predict(X_test)\n",
    "y_test_proba_ada = ada_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"AdaBoost metrics on test data:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred_ada))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred_ada))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred_ada))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_ada))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_ada))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0fe06a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best Gradient Boosting parameters from RandomizedSearchCV: {'subsample': 1.0, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 6, 'learning_rate': 0.01}\n",
      "Best F1 score from Gradient Boosting (RandomizedSearchCV): 0.9954565312389375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set up the Gradient Boosting classifier and parameter distributions\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb_param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5, 1.0],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 6]\n",
    "}\n",
    "\n",
    "gb_random_search = RandomizedSearchCV(\n",
    "    gb,\n",
    "    gb_param_dist,\n",
    "    n_iter=2,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "gb_random_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best Gradient Boosting parameters from RandomizedSearchCV:\", gb_random_search.best_params_)\n",
    "print(\"Best F1 score from Gradient Boosting (RandomizedSearchCV):\", gb_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7750d05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting metrics on test data:\n",
      "Precision: 0.9934640522875817\n",
      "Recall: 0.9967213114754099\n",
      "F1 Score: 0.9950900163666121\n",
      "Accuracy: 0.9953229398663697\n",
      "ROC-AUC: 0.9972985128059788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Set up the Gradient Boosting Classifier with best hyperparameters from RandomizedSearchCV\n",
    "gb_clf = GradientBoostingClassifier(\n",
    "    subsample=1.0,\n",
    "    n_estimators=100,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=4,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.01,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train on resampled data\n",
    "gb_clf.fit(X_res, y_res)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred_gb = gb_clf.predict(X_test)\n",
    "y_test_proba_gb = gb_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Gradient Boosting metrics on test data:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred_gb))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred_gb))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred_gb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_gb))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c50d8dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:08:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:08:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:08:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:08:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:08:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:08:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:08:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:08:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:09:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:10:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:11:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost parameters from RandomizedSearchCV: {'subsample': 1.0, 'reg_lambda': 0.1, 'reg_alpha': 1, 'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.5, 'gamma': 1, 'colsample_bytree': 0.7}\n",
      "Best F1 score from XGBoost (RandomizedSearchCV): 0.997285697806638\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Set up the XGBoost classifier and parameter distributions\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 10],\n",
    "    'subsample': [0.6, 0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 1, 2],\n",
    "    'reg_alpha': [0, 0.01, 0.1, 1],\n",
    "    'reg_lambda': [0.1, 1, 5, 10]\n",
    "}\n",
    "\n",
    "xgb_random_search = RandomizedSearchCV(\n",
    "    xgb,\n",
    "    xgb_param_dist,\n",
    "    n_iter=2,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "xgb_random_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best XGBoost parameters from RandomizedSearchCV:\", xgb_random_search.best_params_)\n",
    "print(\"Best F1 score from XGBoost (RandomizedSearchCV):\", xgb_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "196dceb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [13:08:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost metrics on test data:\n",
      "Precision: 0.9962555581558624\n",
      "Recall: 0.9969555035128805\n",
      "F1 Score: 0.9966054079363221\n",
      "Accuracy: 0.9967706013363029\n",
      "ROC-AUC: 0.9995833271180457\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Set up the XGBoost Classifier with best-found hyperparameters from RandomizedSearchCV\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.5,\n",
    "    max_depth=6,\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=0.7,\n",
    "    gamma=1,\n",
    "    reg_alpha=1,\n",
    "    reg_lambda=0.1,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Train the model on the resampled training data\n",
    "xgb_clf.fit(X_res, y_res)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred_xgb = xgb_clf.predict(X_test)\n",
    "y_test_proba_xgb = xgb_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"XGBoost metrics on test data:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred_xgb))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred_xgb))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred_xgb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_xgb))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be2c112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d406a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0577d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e85a298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
