{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa571a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb4bd17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed/train.csv\", converters={'tokens': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6415f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOILER ROOM: As the Frogs Slowly Boil – EP #40</td>\n",
       "      <td>Tune in to the Alternate Current Radio Network...</td>\n",
       "      <td>US_News</td>\n",
       "      <td>January 20, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>boiler room: as the frogs slowly boil – ep #40...</td>\n",
       "      <td>[boiler, room, frog, slowly, boil, ep, tune, a...</td>\n",
       "      <td>boiler room frog slowly boil ep tune alternate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Venezuela oil boss to give military more P...</td>\n",
       "      <td>CARACAS (Reuters) - A general appointed at the...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 27, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>new venezuela oil boss to give military more p...</td>\n",
       "      <td>[new, venezuela, oil, bos, give, military, pdv...</td>\n",
       "      <td>new venezuela oil bos give military pdvsa post...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkey says talk of ending its EU accession un...</td>\n",
       "      <td>ISTANBUL (Reuters) - Turkey s European Union A...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 4, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>turkey says talk of ending its eu accession un...</td>\n",
       "      <td>[turkey, say, talk, ending, eu, accession, und...</td>\n",
       "      <td>turkey say talk ending eu accession undermines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENATOR GILLIBRAND Pulled Strings So Muslim At...</td>\n",
       "      <td>Democrat Senator Kristen Gillibrand (NY) likes...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Dec 12, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>senator gillibrand pulled strings so muslim at...</td>\n",
       "      <td>[senator, gillibrand, pulled, string, muslim, ...</td>\n",
       "      <td>senator gillibrand pulled string muslim athlet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Republican Trump says 'system is rigged' after...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. Republican preside...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 5, 2016</td>\n",
       "      <td>1</td>\n",
       "      <td>republican trump says 'system is rigged' after...</td>\n",
       "      <td>[republican, trump, say, rigged, clinton, emai...</td>\n",
       "      <td>republican trump say rigged clinton email anno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35913</th>\n",
       "      <td>Trump Just FAILED Hundreds Of Manufacturing W...</td>\n",
       "      <td>Last year, Trump claimed he was succeeding at ...</td>\n",
       "      <td>News</td>\n",
       "      <td>May 7, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>trump just failed hundreds of manufacturing w...</td>\n",
       "      <td>[trump, failed, hundred, manufacturing, worker...</td>\n",
       "      <td>trump failed hundred manufacturing worker blam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35914</th>\n",
       "      <td>Judge Garland not interested in FBI job: sources</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. appeals court judg...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>May 16, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>judge garland not interested in fbi job: sourc...</td>\n",
       "      <td>[judge, garland, interested, fbi, job, source,...</td>\n",
       "      <td>judge garland interested fbi job source washin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35915</th>\n",
       "      <td>Expert On Voting Fraud DESTROYS Trump’s Lies ...</td>\n",
       "      <td>Terrified and unable to accept that he s destr...</td>\n",
       "      <td>News</td>\n",
       "      <td>October 17, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>expert on voting fraud destroys trump’s lies ...</td>\n",
       "      <td>[expert, voting, fraud, destroys, trump, lie, ...</td>\n",
       "      <td>expert voting fraud destroys trump lie blister...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35916</th>\n",
       "      <td>[Video] POLICE HAVE VERY GOOD REASON FOR BLOCK...</td>\n",
       "      <td>This mayor s involvement in potential illegal ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Apr 24, 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>[video] police have very good reason for block...</td>\n",
       "      <td>[video, police, good, reason, blocking, newly,...</td>\n",
       "      <td>video police good reason blocking newly electe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35917</th>\n",
       "      <td>BUSTED! WASHINGTON POST Skips Maxine Waters’ A...</td>\n",
       "      <td>There are 20 Democrats who at certain times ha...</td>\n",
       "      <td>politics</td>\n",
       "      <td>May 10, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>busted! washington post skips maxine waters’ a...</td>\n",
       "      <td>[busted, washington, post, skip, maxine, water...</td>\n",
       "      <td>busted washington post skip maxine water admis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35918 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0         BOILER ROOM: As the Frogs Slowly Boil – EP #40   \n",
       "1      New Venezuela oil boss to give military more P...   \n",
       "2      Turkey says talk of ending its EU accession un...   \n",
       "3      SENATOR GILLIBRAND Pulled Strings So Muslim At...   \n",
       "4      Republican Trump says 'system is rigged' after...   \n",
       "...                                                  ...   \n",
       "35913   Trump Just FAILED Hundreds Of Manufacturing W...   \n",
       "35914   Judge Garland not interested in FBI job: sources   \n",
       "35915   Expert On Voting Fraud DESTROYS Trump’s Lies ...   \n",
       "35916  [Video] POLICE HAVE VERY GOOD REASON FOR BLOCK...   \n",
       "35917  BUSTED! WASHINGTON POST Skips Maxine Waters’ A...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "0      Tune in to the Alternate Current Radio Network...       US_News   \n",
       "1      CARACAS (Reuters) - A general appointed at the...     worldnews   \n",
       "2      ISTANBUL (Reuters) - Turkey s European Union A...     worldnews   \n",
       "3      Democrat Senator Kristen Gillibrand (NY) likes...     left-news   \n",
       "4      WASHINGTON (Reuters) - U.S. Republican preside...  politicsNews   \n",
       "...                                                  ...           ...   \n",
       "35913  Last year, Trump claimed he was succeeding at ...          News   \n",
       "35914  WASHINGTON (Reuters) - U.S. appeals court judg...  politicsNews   \n",
       "35915  Terrified and unable to accept that he s destr...          News   \n",
       "35916  This mayor s involvement in potential illegal ...      politics   \n",
       "35917  There are 20 Democrats who at certain times ha...      politics   \n",
       "\n",
       "                     date  label  \\\n",
       "0        January 20, 2016      0   \n",
       "1      November 27, 2017       1   \n",
       "2      September 4, 2017       1   \n",
       "3            Dec 12, 2017      0   \n",
       "4           July 5, 2016       1   \n",
       "...                   ...    ...   \n",
       "35913         May 7, 2017      0   \n",
       "35914       May 16, 2017       1   \n",
       "35915    October 17, 2016      0   \n",
       "35916        Apr 24, 2015      0   \n",
       "35917        May 10, 2017      0   \n",
       "\n",
       "                                                 content  \\\n",
       "0      boiler room: as the frogs slowly boil – ep #40...   \n",
       "1      new venezuela oil boss to give military more p...   \n",
       "2      turkey says talk of ending its eu accession un...   \n",
       "3      senator gillibrand pulled strings so muslim at...   \n",
       "4      republican trump says 'system is rigged' after...   \n",
       "...                                                  ...   \n",
       "35913   trump just failed hundreds of manufacturing w...   \n",
       "35914  judge garland not interested in fbi job: sourc...   \n",
       "35915   expert on voting fraud destroys trump’s lies ...   \n",
       "35916  [video] police have very good reason for block...   \n",
       "35917  busted! washington post skips maxine waters’ a...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [boiler, room, frog, slowly, boil, ep, tune, a...   \n",
       "1      [new, venezuela, oil, bos, give, military, pdv...   \n",
       "2      [turkey, say, talk, ending, eu, accession, und...   \n",
       "3      [senator, gillibrand, pulled, string, muslim, ...   \n",
       "4      [republican, trump, say, rigged, clinton, emai...   \n",
       "...                                                  ...   \n",
       "35913  [trump, failed, hundred, manufacturing, worker...   \n",
       "35914  [judge, garland, interested, fbi, job, source,...   \n",
       "35915  [expert, voting, fraud, destroys, trump, lie, ...   \n",
       "35916  [video, police, good, reason, blocking, newly,...   \n",
       "35917  [busted, washington, post, skip, maxine, water...   \n",
       "\n",
       "                                              clean_text  \n",
       "0      boiler room frog slowly boil ep tune alternate...  \n",
       "1      new venezuela oil bos give military pdvsa post...  \n",
       "2      turkey say talk ending eu accession undermines...  \n",
       "3      senator gillibrand pulled string muslim athlet...  \n",
       "4      republican trump say rigged clinton email anno...  \n",
       "...                                                  ...  \n",
       "35913  trump failed hundred manufacturing worker blam...  \n",
       "35914  judge garland interested fbi job source washin...  \n",
       "35915  expert voting fraud destroys trump lie blister...  \n",
       "35916  video police good reason blocking newly electe...  \n",
       "35917  busted washington post skip maxine water admis...  \n",
       "\n",
       "[35918 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbd5413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best N-gram range: (1, 2)\n",
      "Best Accuracy score: 0.9956289085185356\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Set max_features for CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define features and labels\n",
    "X = df['clean_text'].values\n",
    "y = df['label'].values  # Ensure your label column is correct\n",
    "\n",
    "# Build pipeline using CountVectorizer\n",
    "pipeline = Pipeline([\n",
    "    ('count', CountVectorizer(stop_words='english')),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Set vocabulary size (optional but recommended)\n",
    "pipeline.named_steps['count'].set_params(max_features=10000)\n",
    "\n",
    "# Define parameter grid for N-gram testing\n",
    "param_grid = {\n",
    "    'count__ngram_range': [(1,1), (1,2), (1,3)]\n",
    "}\n",
    "\n",
    "# Use stratified k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Grid Search to find the best N-gram range\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Print results\n",
    "print(\"Best N-gram range:\", grid.best_params_['count__ngram_range'])\n",
    "print(\"Best Accuracy score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "777cf488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "\n",
    "# Apply CountVectorizer feature engineering with ngram_range (1,2) and max_features=10000\n",
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 2), max_features=10000)\n",
    "count_features = count_vectorizer.fit_transform(df['clean_text'].values)\n",
    "\n",
    "# Save the Count matrix and the vectorizer as a tuple to pickle file\n",
    "with open('count_features_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump((count_features, count_vectorizer), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256936e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/home/root495/Inexture/Fake New Detection/count_features_ngram.pkl', 'rb') as f:\n",
    "    count_features, count_vectorizer = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ecaec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE: {0: 18771, 1: 18771}\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Use the same X and y as above\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(count_features, df['label'].values)\n",
    "\n",
    "print(\"Class distribution after SMOTE:\", dict(zip(*np.unique(y_res, return_counts=True))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288bf5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"data/processed/test.csv\")\n",
    "\n",
    "# Transform test data into TF-IDF representation using the fitted vectorizer\n",
    "X_test = count_vectorizer.transform(test_df['clean_text'].values)\n",
    "y_test = test_df[\"label\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce68c16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best F1 score from Logistic Regression: 0.9937045587665814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Use the count-based features (replace with coutfeatures)\n",
    "\n",
    "# Set up the Logistic Regression and parameter grid\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'saga']\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best Logistic Regression parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 score from Logistic Regression:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc8a8cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression metrics on test data:\n",
      "Precision: 0.9957815795640965\n",
      "Recall: 0.9950819672131147\n",
      "F1 Score: 0.9954316504626918\n",
      "Accuracy: 0.9956570155902005\n",
      "ROC-AUC: 0.9986908118160076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "# Train logistic regression on balanced data with best found hyperparameters\n",
    "logreg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    C=0.1,\n",
    "    penalty='l2',\n",
    "    solver='lbfgs'\n",
    ")\n",
    "logreg.fit(X_res, y_res)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "y_test_proba = logreg.predict_proba(X_test)[:,1] \n",
    "\n",
    "print(\"Logistic Regression metrics on test data:\")\n",
    "\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "918303e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Naive Bayes parameters: {'alpha': 0.01, 'fit_prior': True}\n",
      "Best F1 score from Naive Bayes: 0.9602126982634818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Set up the Naive Bayes classifier and parameter grid\n",
    "nb = MultinomialNB()\n",
    "nb_param_grid = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1, 2, 5, 10],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "nb_grid_search = GridSearchCV(nb, nb_param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "nb_grid_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best Naive Bayes parameters:\", nb_grid_search.best_params_)\n",
    "print(\"Best F1 score from Naive Bayes:\", nb_grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a192ba76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes metrics on test data:\n",
      "Precision: 0.9517177344475395\n",
      "Recall: 0.9601873536299765\n",
      "F1 Score: 0.9559337840988575\n",
      "Accuracy: 0.9579064587973274\n",
      "ROC-AUC: 0.9824364424688117\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Train Naive Bayes with best parameters\n",
    "nb_best = MultinomialNB(alpha=0.01, fit_prior=True)\n",
    "nb_best.fit(X_res, y_res)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred_nb = nb_best.predict(X_test)\n",
    "y_test_proba_nb = nb_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Naive Bayes metrics on test data:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred_nb))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred_nb))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred_nb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_nb))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f2ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree metrics on test data:\n",
      "Precision: 0.9913611954237684\n",
      "Recall: 0.9943793911007026\n",
      "F1 Score: 0.9928679995323278\n",
      "Accuracy: 0.9932071269487751\n",
      "ROC-AUC: 0.9932618823868694\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee40c643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree parameters: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Best F1 score from Decision Tree: 0.993871161529096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Set up the Decision Tree classifier and parameter grid\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt_param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [None, 5, 10, 20, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "dt_grid_search = GridSearchCV(dt, dt_param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "dt_grid_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best Decision Tree parameters:\", dt_grid_search.best_params_)\n",
    "print(\"Best F1 score from Decision Tree:\", dt_grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd247ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree metrics on test data:\n",
      "Precision: 0.994154781388824\n",
      "Recall: 0.9957845433255269\n",
      "F1 Score: 0.9949689949689949\n",
      "Accuracy: 0.9952115812917595\n",
      "ROC-AUC: 0.9945250277201828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train Decision Tree with best parameters\n",
    "dt_best = DecisionTreeClassifier(\n",
    "    criterion='gini', \n",
    "    max_depth=20, \n",
    "    min_samples_leaf=2, \n",
    "    min_samples_split=5, \n",
    "    random_state=42\n",
    ")\n",
    "dt_best.fit(X_res, y_res)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred_dt = dt_best.predict(X_test)\n",
    "y_test_proba_dt = dt_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Decision Tree metrics on test data:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred_dt))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred_dt))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred_dt))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_dt))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d68002bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/root495/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:516: FitFailedWarning: \n",
      "35 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/root495/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/root495/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/root495/.local/lib/python3.10/site-packages/sklearn/base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/root495/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1135: UserWarning: One or more of the test scores are non-finite: [0.98613506 0.9968356  0.98240674 0.99230187 0.95864211        nan\n",
      " 0.93403916        nan 0.96471658        nan 0.96835223 0.99269937\n",
      "        nan        nan 0.97788846        nan        nan 0.96629331\n",
      " 0.98692514 0.97705398]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest parameters from RandomizedSearchCV: {'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
      "Best F1 score from Random Forest (RandomizedSearchCV): 0.9968355960169879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set up the Random Forest classifier and parameter distributions\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'max_depth': [None, 5, 10, 20, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    rf,\n",
    "    rf_param_dist,\n",
    "    n_iter=20,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "rf_random_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best Random Forest parameters from RandomizedSearchCV:\", rf_random_search.best_params_)\n",
    "print(\"Best F1 score from Random Forest (RandomizedSearchCV):\", rf_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8ef4c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest metrics on test data:\n",
      "Precision: 0.9570411210659315\n",
      "Recall: 0.9756440281030445\n",
      "F1 Score: 0.9662530441841587\n",
      "Accuracy: 0.9675946547884187\n",
      "ROC-AUC: 0.9933310461074897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest with (changed) parameters\n",
    "rf_best = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='log2',\n",
    "    max_depth=10,\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "rf_best.fit(X_res, y_res)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred_rf = rf_best.predict(X_test)\n",
    "y_test_proba_rf = rf_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest metrics on test data:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_rf))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef586d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:516: FitFailedWarning: \n",
      "55 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/root495/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/root495/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/root495/.local/lib/python3.10/site-packages/sklearn/base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/root495/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'algorithm' parameter of AdaBoostClassifier must be a str among {'SAMME'}. Got 'SAMME.R' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1135: UserWarning: One or more of the test scores are non-finite: [0.99158599 0.99158599        nan        nan 0.99184872        nan\n",
      "        nan        nan 0.99171754        nan        nan        nan\n",
      "        nan 0.99158599        nan 0.99282228 0.99158599 0.99158599\n",
      "        nan 0.99158599]\n",
      "  warnings.warn(\n",
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost parameters from RandomizedSearchCV: {'n_estimators': 200, 'learning_rate': 0.5, 'algorithm': 'SAMME'}\n",
      "Best F1 score from AdaBoost (RandomizedSearchCV): 0.9928222840334244\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set up the AdaBoost classifier and parameter distributions\n",
    "ada = AdaBoostClassifier(random_state=42)\n",
    "ada_param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0, 2.0],\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "ada_random_search = RandomizedSearchCV(\n",
    "    ada,\n",
    "    ada_param_dist,\n",
    "    n_iter=20,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "ada_random_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best AdaBoost parameters from RandomizedSearchCV:\", ada_random_search.best_params_)\n",
    "print(\"Best F1 score from AdaBoost (RandomizedSearchCV):\", ada_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7548da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/root495/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost metrics on test data:\n",
      "Precision: 0.9906933457422057\n",
      "Recall: 0.9971896955503513\n",
      "F1 Score: 0.9939309056956116\n",
      "Accuracy: 0.9942093541202672\n",
      "ROC-AUC: 0.9991922612210802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Train AdaBoost with best parameters from RandomizedSearchCV\n",
    "ada_best = AdaBoostClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.5,\n",
    "    algorithm='SAMME',\n",
    "    random_state=42\n",
    ")\n",
    "ada_best.fit(X_res, y_res)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred_ada = ada_best.predict(X_test)\n",
    "y_test_proba_ada = ada_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"AdaBoost metrics on test data:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred_ada))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred_ada))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred_ada))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_ada))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_ada))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0fe06a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best Gradient Boosting parameters from RandomizedSearchCV: {'subsample': 1.0, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 6, 'learning_rate': 0.01}\n",
      "Best F1 score from Gradient Boosting (RandomizedSearchCV): 0.9935664226558136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set up the Gradient Boosting classifier and parameter distributions\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb_param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5, 1.0],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 6]\n",
    "}\n",
    "\n",
    "gb_random_search = RandomizedSearchCV(\n",
    "    gb,\n",
    "    gb_param_dist,\n",
    "    n_iter=2,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "gb_random_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best Gradient Boosting parameters from RandomizedSearchCV:\", gb_random_search.best_params_)\n",
    "print(\"Best F1 score from Gradient Boosting (RandomizedSearchCV):\", gb_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7dc843e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting metrics on test data:\n",
      "Precision: 0.992081974848626\n",
      "Recall: 0.9976580796252927\n",
      "F1 Score: 0.9948622139187295\n",
      "Accuracy: 0.9951002227171493\n",
      "ROC-AUC: 0.9977608307602042\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Set up the Gradient Boosting Classifier with best found hyperparameters from RandomizedSearchCV\n",
    "gb_clf = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=6,\n",
    "    subsample=1.0,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train on resampled data\n",
    "gb_clf.fit(X_res, y_res)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred_gb = gb_clf.predict(X_test)\n",
    "y_test_proba_gb = gb_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Gradient Boosting metrics on test data:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred_gb))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred_gb))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred_gb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_gb))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c50d8dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:17] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:34:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:35:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:36:59] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [23:37:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost parameters from RandomizedSearchCV: {'subsample': 0.8, 'reg_lambda': 5, 'reg_alpha': 0.1, 'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.05, 'gamma': 0.1, 'colsample_bytree': 1.0}\n",
      "Best F1 score from XGBoost (RandomizedSearchCV): 0.9976046555707073\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Set up the XGBoost classifier and parameter distributions\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 10],\n",
    "    'subsample': [0.6, 0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 1, 2],\n",
    "    'reg_alpha': [0, 0.01, 0.1, 1],\n",
    "    'reg_lambda': [0.1, 1, 5, 10]\n",
    "}\n",
    "\n",
    "xgb_random_search = RandomizedSearchCV(\n",
    "    xgb,\n",
    "    xgb_param_dist,\n",
    "    n_iter=20,\n",
    "    cv=cv,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "xgb_random_search.fit(X_res, y_res)\n",
    "\n",
    "print(\"Best XGBoost parameters from RandomizedSearchCV:\", xgb_random_search.best_params_)\n",
    "print(\"Best F1 score from XGBoost (RandomizedSearchCV):\", xgb_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1be2c112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/root495/.local/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:09:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost metrics on test data:\n",
      "Precision: 0.9971903535471787\n",
      "Recall: 0.997423887587822\n",
      "F1 Score: 0.997307106896148\n",
      "Accuracy: 0.9974387527839643\n",
      "ROC-AUC: 0.9996625844657587\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Set up the XGBoost Classifier with best hyperparameters found by RandomizedSearchCV\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=1.0,\n",
    "    gamma=0.1,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=5,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Train the model on the resampled training data\n",
    "xgb_clf.fit(X_res, y_res)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred_xgb = xgb_clf.predict(X_test)\n",
    "y_test_proba_xgb = xgb_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"XGBoost metrics on test data:\")\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred_xgb))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred_xgb))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred_xgb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_xgb))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba_xgb))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
